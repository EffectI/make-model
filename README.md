![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange) ![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-Hugging%20Face-yellow) ![License](https://img.shields.io/badge/License-MIT-green)
````markdown
# ğŸ¤– AI-Text-Classifier (Lightweight Model Project)

EDA

# 1. ë°ì´í„° ê¸°ë³¸ êµ¬ì¡°
   
python eda.py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 97172 entries, 0 to 97171
Data columns (total 3 columns):
 #   Column     Non-Null Count  Dtype
---  ------     --------------  -----
 0   title      97172 non-null  object
 1   full_text  97172 non-null  object
 2   generated  97172 non-null  int64
dtypes: int64(1), object(2)
memory usage: 2.2+ MB

- ì „ì²´ 97,172ê°œ ë¬¸ì„œë¡œ êµ¬ì„±
- generated: 0(Human) / 1(AI)
- ë ˆì´ë¸” ë¹„ìœ¨: 89,177(0) : 7,995(1) â‰ˆ 11:1ì˜ ê°•í•œ ë¶ˆê· í˜• ì¡´ì¬

â†’ ì´í›„ ëª¨ë¸ í•™ìŠµ ì‹œ downsampling ë˜ëŠ” re-weighting í•„ìš”í•¨.

# 2. Special Character Pattern Analysis (íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´ ë¶„ì„)

ì‚¬ìš©ëœ íŒ¨í„´:
chinese_char, html_tag, empty_parens, qmark_pattern, repeated_dots, repeated_parens, repeated_commas

<img width="1000" height="925" alt="boxblot grouped by generated" src="https://github.com/user-attachments/assets/5e881d69-a0f7-4e5e-bd56-b9df3a11fd17" />
<img width="500" height="400" alt="boxplot grouped by generated empty parens (log scale)" src="https://github.com/user-attachments/assets/bb9a4ae2-2f11-4cb0-a282-185e82c068e6" />
<img width="500" height="400" alt="boxplot grouped by generated qmark paterns (log scale)" src="https://github.com/user-attachments/assets/70d81c06-690d-4dc1-bb79-d9c4f58356d6" />
<img width="500" height="400" alt="boxplot grouped by generated repeated commas (log scale)" src="https://github.com/user-attachments/assets/12159376-750c-4688-8594-b9d55cccb123" />
<img width="500" height="400" alt="boxplot grouped by generated repeated dots (log scale)" src="https://github.com/user-attachments/assets/82535283-a7b1-423f-bb43-b2cff97d66f4" />
<img width="500" height="400" alt="boxplot grouped by generated repeated parens (log scale)" src="https://github.com/user-attachments/assets/4c1bd1e6-f3f0-467a-9cb8-f52e6a8cba84" />
<img width="999" height="399" alt="Effect Size (Cohen&#39;s d) for Pattern Features" src="https://github.com/user-attachments/assets/7c098e28-acd0-4191-865e-5a4cedef1acb" />
<img width="1489" height="988" alt="Special Character Pattern Comparison (Human vs AI" src="https://github.com/user-attachments/assets/dcc36df9-5eb0-44e4-b0a9-4e7ea33db5e3" />
<img width="599" height="299" alt="Stylistic Feature Means (Human vs AI)" src="https://github.com/user-attachments/assets/23b13c0f-a79a-4a11-9e0b-920879381bac" />

í•œì, HTML Tag, ë°˜ë³µ ê´„í˜¸/ë§ˆì¹¨í‘œ/ì‰¼í‘œ ë“± ì´ 7ê°œ íŒ¨í„´ì„ ë¶„ì„í•œ ê²°ê³¼,
Humanâ€“AI ê°„ ì°¨ì´ëŠ” ì¡´ì¬í•˜ë‚˜ ì ˆëŒ€ì  í¬ê¸°ê°€ ë§¤ìš° ì‘ê³  êµ¬ë¶„ë ¥ì´ ë‚®ìŒì„ í™•ì¸í•¨.

ë¶„ì„ ê²°ê³¼ ìš”ì•½

| Pattern         | Human | AI    | ì°¨ì´    |
| --------------- | ----- | ----- | -----   |
| chinese_char    | 11.7  | 6.5   | ì•½ 5ê°œ  |
| html_tag        | 0.125 | 0.099 | 0.02ê°œ  |
| repeated_parens | 0.031 | 0.017 | 0.01ê°œ  |

ê²°ë¡ 
- ëª¨ë“  íŒ¨í„´ì˜ ì ˆëŒ€ê°’ì´ ë„ˆë¬´ ì‘ìŒ (ê±°ì˜ 0~0.1ëŒ€).
- Cohenâ€™s d íš¨ê³¼í¬ê¸° ì—­ì‹œ ì „ë¶€ 0.1 ì´í•˜(= ë§¤ìš° ì‘ì€ íš¨ê³¼).
 â†’ êµ¬ë¶„ë ¥ ê·¹íˆ ë‚®ìŒ
 â†’ Featureë¡œ ì‚¬ìš© ì‹œ ëª¨ë¸ ì„±ëŠ¥ì— ê¸°ì—¬ ë¶ˆê°€
 â†’ ì „ì²˜ë¦¬(íŠ¹ìˆ˜ë¬¸ì ì œê±°) ë‹¨ê³„ì—ì„œë§Œ ì‚¬ìš©í•˜ê³  Featureì—ì„œëŠ” ì œì™¸í•¨


# 3. ì–¸ì–´ëª¨ë¸ ê¸°ë°˜ Metric: Perplexity & Entropy

ì‚¬ìš© ì´ë¯¸ì§€ë“¤
<img width="1184" height="648" alt="Entrpy Distribution" src="https://github.com/user-attachments/assets/abe8ca5b-7f77-4fab-9212-5ca0630d4ccc" />
<img width="1184" height="648" alt="Perplexity Distribution (Log Scale)" src="https://github.com/user-attachments/assets/2f3aa5e7-74fd-416a-85f6-e11352b26670" />
<img width="1184" height="816" alt="Perplexity vs Entropy" src="https://github.com/user-attachments/assets/39a172de-63be-4131-8a7c-7b2ff482972e" />

ë¶„ì„ ê²°ê³¼

Human ë¬¸ì„œ
- Perplexity ë¶„í¬ í­ì´ ë„“ê³  í‰ê· ì´ ë†’ìŒ
- LMì´ ì˜ˆì¸¡í•˜ê¸° ì–´ë ¤ìš´ ë¬¸ì¥ êµ¬ì¡° â†’ perplexityâ†‘ / entropyâ†‘

AI ë¬¸ì„œ
- ì˜ˆì¸¡ íŒ¨í„´ì´ ì •í˜•ì  â†’ perplexityâ†“, entropyâ†“
- ë¶„í¬ê°€ ì¢ê³  ì•ˆì •ì 

í•µì‹¬ ê²°ë¡ 
- PerplexityëŠ” Humanâ€“AIë¥¼ ë‚˜ëˆ„ëŠ” ê°€ì¥ ê°•ë ¥í•œ Feature
- ê¸¸ì´Â·íŠ¹ìˆ˜ë¬¸ì ê¸°ë°˜ Featureë³´ë‹¤ êµ¬ë¶„ ì„±ëŠ¥(AUC) ê¸°ì—¬ë„ê°€ ì••ë„ì 

# 4. í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„ (Length Distribution + KDE)

<img width="1200" height="500" alt="boxplot text_len word_count" src="https://github.com/user-attachments/assets/3e1485fe-84d2-44dd-91fb-d54d514dbebf" />
<img width="640" height="480" alt="length vs word count scatter" src="https://github.com/user-attachments/assets/582d5903-49a6-4141-accc-a4c64d1597cd" />
<img width="640" height="480" alt="text length distribution (log scale)" src="https://github.com/user-attachments/assets/5b8fb3e7-23e7-4339-b1a2-1199dfbcae50" />
<img width="799" height="499" alt="Text Length Distribution (log scale, with KDE)" src="https://github.com/user-attachments/assets/282d32de-9d6d-4ff4-95ae-2c81d22a31ef" />
<img width="1184" height="648" alt="Text Length Statistics by Label" src="https://github.com/user-attachments/assets/ac754680-743b-46fd-8821-81d21f267c21" />
<img width="1222" height="648" alt="Text Length Summary (by Label)" src="https://github.com/user-attachments/assets/4b3ae0ac-8362-4044-941c-865ba7c964ef" />

ì •ëŸ‰ ë¶„ì„
| Metric | Human  | AI     | Insight              |
| ------ | ------ | ------ | ---------------      |
| Mean   | 2325   | 2298   | Humanì´ ì•½ê°„ ê¸¸ë‹¤     |
| Median | 1331   | 1334   | ê±°ì˜ ë™ì¼             |
| Std    | 3351   | 3131   | Human ë³€ë™ì„±â†‘         |
| Max    | 98,549 | 46,814 | Human ê·¹ë‹¨ì  ì¥ë¬¸ ì¡´ì¬ |


Histogram + KDE ê²°ê³¼ Humanê³¼ AI ë¬¸ì„œ ê¸¸ì´ ë¶„í¬ì— ëšœë ·í•œ ì°¨ì´ê°€ í™•ì¸ë¨.

Human í…ìŠ¤íŠ¸
- ë§¤ìš° ì§§ì€ ê¸€ë¶€í„° ë§¤ìš° ê¸´ ê¸€ê¹Œì§€ ë²”ìœ„ ì „ë°˜ì— ë¶„í¬
- ë¬¸ì„œ ê¸¸ì´ì˜ ë¶ˆê·œì¹™ì„±Â·ë‹¤ì–‘ì„±â†‘

AI í…ìŠ¤íŠ¸
- íŠ¹ì • ê¸¸ì´ êµ¬ê°„(ì˜ˆ: 300~1,000 tokens)ì— ë°€ì§‘
- ìƒì„± ëª¨ë¸ì˜ ì¶œë ¥ ê¸¸ì´ê°€ ì¼ì •í•œ ê·œì¹™ì„±ì„ ê°€ì§

â†’ ë¬¸ì„œ ê¸¸ì´ë§Œìœ¼ë¡œë„ weak classifier ì—­í•  ê°€ëŠ¥.

ê²°ë¡ 
- Human ë¬¸ì„œëŠ” ë§¤ìš° ì§§ì€ ê¸€~ìˆ˜ ë§Œ ë‹¨ì–´ê¹Œì§€ í­ë„“ê²Œ ë¶„í¬
- AI ë¬¸ì„œëŠ” 300~1,000 tokens ë¶€ê·¼ì— ì§‘ì¤‘ë˜ëŠ” ê²½í–¥
â†’ ë¬¸ì„œ ê¸¸ì´ë§Œìœ¼ë¡œë„ ì•½í•œ ë¶„ë¥˜ê¸°(weak classifier) ì—­í•  ê°€ëŠ¥


# 5. Lexical Diversity (ì–´íœ˜ ë‹¤ì–‘ì„±, TTR: Typeâ€“Token Ratio)

ì‚¬ìš© ì´ë¯¸ì§€
<img width="640" height="480" alt="lexical diversity _ type-toke ratio" src="https://github.com/user-attachments/assets/8703ea2f-cc6a-429e-a528-9808d7183f4d" />
<img width="499" height="499" alt="Type-Token Ratio by Class" src="https://github.com/user-attachments/assets/c66f2cfc-e3d0-4b8c-bc3d-51ab8223552c" />

ë¶„ì„ ê²°ê³¼

Human
- ë‹¤ì–‘í•œ í‘œí˜„Â·ë‹¨ì–´ ì‚¬ìš©
- ë¬¸ì¥ êµ¬ì¡°Â·ì£¼ì œ ì „í™˜ì´ ììœ ë¡œì›Œ ì–´íœ˜ ë¶„í¬ í­ì´ ë„“ìŒ
- TTR ë†’ìŒ
â†’ ë‹¤ì–‘í•œ í‘œí˜„Â·ë‹¨ì–´ ì¡°í•© â†’ TTR ë†’ìŒ

AI
- ë™ì¼ í‘œí˜„ ë°˜ë³µ
- ë¬¸ì¥ íŒ¨í„´ì˜ ê·œì¹™ì„±
- TTR ë‚®ìŒ
â†’ AI: ë°˜ë³µì  í‘œí˜„Â·ì •í˜• íŒ¨í„´ â†’ TTR ë‚®ìŒ

â†’ ë¬¸ì²´ì  ë³€ë™ì„± ìì²´ê°€ Humanì˜ ì¤‘ìš”í•œ ì‹œê·¸ë„ë¡œ ì‘ë™í•¨

# 6. Stylistic Analysis (ë¬¸ì²´ ë¶„ì„)

ì‚¬ìš© ì´ë¯¸ì§€ 
<img width="599" height="299" alt="Stylistic Feature Means (Human vs AI)" src="https://github.com/user-attachments/assets/951f7936-e99d-42c5-b2e5-7328f27f9150" />

ë¬¸ì¥ ê¸¸ì´ ë³€í™”, ë¬¸ì¥ë¶€í˜¸ íŒ¨í„´, ë¶ˆìš©ì–´ ë¹„ìœ¨, êµ¬ì¡°ì  ë‹¤ì–‘ì„±ì„ ì •ëŸ‰í™”í•¨.

Human ë¬¸ì²´
- ë¬¸ì¥ ê¸¸ì´ì˜ ë¶„ì‚°ì´ í¼
- ì‰¼í‘œ/ì½œë¡ /ëŒ€ì‹œ ë“± ë‹¤ì–‘í•œ ë¶€í˜¸ ì‚¬ìš©
- ì£¼ì œ ì „í™˜ê³¼ íë¦„ ë³€í™”ê°€ ë¹ˆë²ˆ
â†’ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´ì  ë³€ë™ì„±

AI ë¬¸ì²´
- ë¬¸ì¥ ê¸¸ì´ê°€ ê·œì¹™ì ì¸ íŒ¨í„´ìœ¼ë¡œ ì •ë ¬
- â€˜í•˜ì§€ë§Œâ€™, â€˜ë”°ë¼ì„œâ€™, â€˜ë˜í•œâ€™ ë“± ì—°ê²°ì–´ ë°˜ë³µ
- ë¶€í˜¸ ì‚¬ìš© ë°©ì‹ì´ ì¼ì •
â†’ ê¸°ê³„ì  ì¼ê´€ì„±

â†’ ë¬¸ì²´ ë¶„ì„ì€ ì˜ë¯¸ ìˆëŠ” ë³´ì¡° Featureë¡œ í™œìš© ê°€ëŠ¥.

# 7. í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì´ìƒì¹˜Â·ì¤‘ë³µ íƒì§€ (TF-IDF Cosine Similarity)

TF-IDF ê¸°ë°˜ ë¬¸ì„œ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•œ ê²°ê³¼:

AI ë¬¸ì„œ
- ë†’ì€ ìœ ì‚¬ë„ í´ëŸ¬ìŠ¤í„° ì¡´ì¬
- 0.8~0.95 ì´ìƒì˜ ìœ ì‚¬ë„ ê·¸ë£¹ì´ ë‹¤ìˆ˜
- LLMì˜ ë°˜ë³µì  ìƒì„± íŒ¨í„´ì´ í™•ì—°í•¨

Human ë¬¸ì„œ
- ìœ ì‚¬ë„ ë¶„í¬ í­ì´ ë„“ê³  ë‹¤ì–‘ì„± ì¡´ì¬
- ê³ ìœ  ë¬¸ì²´ë¡œ ì¸í•´ ìœ ì‚¬ë„ê°€ ë‚®ê²Œ ë¶„ì‚°ë¨

â†’ ìœ ì‚¬ë„ ë¶„ì„ìœ¼ë¡œ AI ë¬¸ì„œì˜ ë°˜ë³µ ìƒì„± í–‰íƒœë¥¼ íš¨ê³¼ì ìœ¼ë¡œ íƒì§€ ê°€ëŠ¥.

# 8. EDA ì¢…í•© ê²°ë¡ 

- Human í…ìŠ¤íŠ¸ëŠ” ê¸¸ì´Â·ë¬¸ì²´Â·ì–´íœ˜ ë‹¤ì–‘ì„±ì—ì„œ ë†’ì€ ë³€ë™ì„±ì„ ë³´ì„
- AI í…ìŠ¤íŠ¸ëŠ” ê¸¸ì´Â·ë¬¸ì²´Â·íŒ¨í„´ì´ ì¼ì •í•œ ê·œì¹™ì„±ì„ ê°€ì§
- íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´ 7ì¢…ì€ êµ¬ë¶„ë ¥ ê±°ì˜ ì—†ìŒ â†’ Feature ì œì™¸
- Perplexity/EntropyëŠ” ê°€ì¥ ê°•ë ¥í•œ í™•ë¥  ê¸°ë°˜ Feature
- ìœ ì‚¬ë„ ë¶„ì„ì—ì„œ AI ë¬¸ì„œ íŠ¹ìœ ì˜ ë†’ì€ ë°˜ë³µì„±ì´ ëª…í™•íˆ ë“œëŸ¬ë‚¨
- ìµœì¢…ì ìœ¼ë¡œ ê¸¸ì´Â·ë‹¤ì–‘ì„±Â·ë¬¸ì²´Â·LM ê¸°ë°˜ Featureê°€ Humanâ€“AI ë¶„ë¥˜ì˜ í•µì‹¬ ìš”ì†Œì„



## ğŸ“– ê°œìš” (Overview)

ë³¸ í”„ë¡œì íŠ¸ëŠ” **AI ìƒì„± í…ìŠ¤íŠ¸ì™€ ì¸ê°„ ì‘ì„± í…ìŠ¤íŠ¸ë¥¼ íƒì§€ ë° ë¶„ë¥˜**í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM)ë³´ë‹¤ëŠ” **ê²½ëŸ‰í™”ëœ ëª¨ë¸(Lightweight Models)**ì„ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì¶”ë¡  ì„±ëŠ¥ì„ í™•ë³´í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

**í•µì‹¬ ëª©í‘œ:**
* **ë°ì´í„° íŒŒì´í”„ë¼ì¸:** ì „ì²˜ë¦¬ ë° 4-Fold êµì°¨ ê²€ì¦ ë°ì´í„°ì…‹ êµ¬ì¶•
* **ëª¨ë¸ë§:** `klue/roberta-small`, `koelectra-small` ë“± ê²½ëŸ‰ ëª¨ë¸ ê¸°ë°˜ Fine-tuning
* **ì„±ëŠ¥ ê·¹ëŒ€í™”:** 4-Fold ì•™ìƒë¸”(Ensemble)ì„ í†µí•œ ì¼ë°˜í™” ì„±ëŠ¥ ë° ì •í™•ë„ í–¥ìƒ

---

## ğŸ“‚ í´ë” êµ¬ì¡° (Project Structure)

```text
make-model/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # [ìˆ˜ì • ê¸ˆì§€] ì›ë³¸ ë°ì´í„° (train.csv, test.csv)
â”‚   â”œâ”€â”€ interim/           # ì¤‘ê°„ ì •ì œ ë°ì´í„° (clean_train.csv ë“±)
â”‚   â””â”€â”€ fold/              # í•™ìŠµìš© 4-Fold ë¶„í•  ë°ì´í„°ì…‹
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ result_models/     # í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ ì €ì¥ì†Œ (.pth, .bin)
â”‚   â”œâ”€â”€ Klue_roberta-small.ipynb  # ëª¨ë¸ í•™ìŠµìš© ë…¸íŠ¸ë¶ A
â”‚   â”œâ”€â”€ koelectra-small.ipynb     # ëª¨ë¸ í•™ìŠµìš© ë…¸íŠ¸ë¶ B
â”‚   â””â”€â”€ ... 
â”œâ”€â”€ Data Preprocessing.ipynb      # [Step 1] ì „ì²˜ë¦¬ ë° ë°ì´í„° ë¶„í• 
â”œâ”€â”€ Ensemble.ipynb                # [Step 2] ìµœì¢… ì•™ìƒë¸” ë° ì¶”ë¡ 
â””â”€â”€ README.md
````

> **âš ï¸ ì£¼ì˜ì‚¬í•­:**
> ëª¨ë“  Notebook íŒŒì¼ì€ **í”„ë¡œì íŠ¸ ìµœìƒìœ„(`make-model/`) í´ë”ë¥¼ ê¸°ì¤€**ìœ¼ë¡œ ê²½ë¡œê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
> í•˜ìœ„ í´ë”ë¡œ íŒŒì¼ì„ ì´ë™ì‹œí‚¤ê±°ë‚˜, ì‘ì—… ê²½ë¡œ(Current Working Directory)ê°€ ë‹¤ë¥¼ ê²½ìš° ê²½ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

-----

## ğŸš€ ì‹¤í–‰ ê°€ì´ë“œ (Workflow)

í”„ë¡œì íŠ¸ëŠ” ì•„ë˜ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì•¼ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•©ë‹ˆë‹¤.

### 1ï¸âƒ£ Step 1: ë°ì´í„° ì „ì²˜ë¦¬

  * **íŒŒì¼:** `Data Preprocessing.ipynb`
  * **ì„¤ëª…:** ì›ë³¸ ë°ì´í„°(`data/raw`)ì˜ íŠ¹ìˆ˜ë¬¸ì ì œê±°, ë°ì´í„° ì •ì œ í›„ `processed` í´ë”ì— ì €ì¥í•˜ê³ , 4-Fold ê²€ì¦ìš© ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.

### 2ï¸âƒ£ Step 2: ëª¨ë¸ í•™ìŠµ (Training)

  * **íŒŒì¼:** `model/` í´ë” ë‚´ì˜ ê° ëª¨ë¸ë³„ ë…¸íŠ¸ë¶ (ì˜ˆ: `Klue_roberta-small.ipynb`)
  * **ì„¤ëª…:** ìƒì„±ëœ 4-Fold ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. í•™ìŠµëœ ëª¨ë¸ì€ `model/result_models/`ì— ì €ì¥ë©ë‹ˆë‹¤.

### 3ï¸âƒ£ Step 3: ì•™ìƒë¸” ë° ì¶”ë¡  (Inference)

  * **íŒŒì¼:** `Ensemble.ipynb`
  * **ì„¤ëª…:** ê° Foldì—ì„œ í•™ìŠµëœ ëª¨ë¸ë“¤ì„ ë¶ˆëŸ¬ì™€ **Soft Voting** ë°©ì‹ìœ¼ë¡œ ì•™ìƒë¸”í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼(`submission.csv`)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

-----

## ğŸ’» ì‹œì‘í•˜ê¸° (Getting Started)

íŒ€ì› í™˜ê²½ ì„¸íŒ…ì„ ìœ„í•´ ì•„ë˜ ì ˆì°¨ë¥¼ ë”°ë¼ì£¼ì„¸ìš”.

### 1\. í™˜ê²½ ì„¤ì • (Installation)

í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
pip install -r requirements.txt
```

### 2\. ë°ì´í„° íŒŒì¼ ë°°ì¹˜ (Data Setup)

ë³´ì•ˆ ë° ìš©ëŸ‰ ë¬¸ì œë¡œ ë°ì´í„° íŒŒì¼ì€ Gitì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ê³µìœ ë°›ì€ `train.csv`, `test.csv` íŒŒì¼ì„ ì•„ë˜ ê²½ë¡œì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.

```text
make-model/data/raw/train.csv
make-model/data/raw/test.csv
```

-----

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ (Experiment Results)

ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ì™€ ì‹¤í—˜ ì¡°ê±´ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµí‘œì…ë‹ˆë‹¤.

| Model Name | Backbone | F1-Score | Accuracy | Note |
| :--- | :--- | :---: | :---: | :--- |
| **KLUE RoBERTa** | `klue/roberta-small` | 0.0000 | 0.0000 | Baseline |
| **KoELECTRA** | `monologg/koelectra-small` | 0.0000 | 0.0000 | - |
| **Ensemble (Soft)** | 4-Fold Integration | **0.0000** | **0.0000** | Best Performance |

> **Note:**
>
>   * **Metric:** Macro F1-Score ë° Accuracy ê¸°ì¤€
>   * **Environment:** Google Colab T4 / Local GPU (RTX 3060)

```
```