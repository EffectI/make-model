import os
import gc
import torch
import pandas as pd
import numpy as np
from tqdm import tqdm
from scipy.stats import rankdata # [ì¶”ê°€ë¨] Rank Averagingì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from torch.utils.data import DataLoader, Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel, PeftConfig  # [ì¤‘ìš”] LoRA ë¡œë”©ì„ ìœ„í•œ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ==========================================
# [1] ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ==========================================
TEST_FILE_PATH = 'make-model/data/raw/test.csv'   # ì‹¤ì œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ í™•ì¸ í•„ìš”
MODEL_ROOT_DIR = 'make-model/model/result_models/koelectra_small_lora'
OUTPUT_SUBMISSION_PATH = 'make-model/temp_submission/submission_koelectra_rank.csv'

N_FOLDS = 4
BATCH_SIZE = 64
MAX_LEN = 512
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print(f"âš™ï¸ ì„¤ì • í™•ì¸:")
print(f"   - Input: {TEST_FILE_PATH}")
print(f"   - Model Root: {MODEL_ROOT_DIR}")
print(f"   - Device: {DEVICE}")

# ì €ì¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
output_dir = os.path.dirname(OUTPUT_SUBMISSION_PATH)
if output_dir and not os.path.exists(output_dir):
    os.makedirs(output_dir)

# ==========================================
# [2] ë°ì´í„°ì…‹ í´ë˜ìŠ¤
# ==========================================
class TestDataset(Dataset):
    def __init__(self, df, tokenizer, max_len):
        self.texts = df['text'].values
        self.tokenizer = tokenizer
        self.max_len = max_len
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, index):
        text = str(self.texts[index])
        inputs = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_len,
            return_tensors='pt'
        )
        return {
            'input_ids': inputs['input_ids'].squeeze(0),
            'attention_mask': inputs['attention_mask'].squeeze(0)
        }

# ==========================================
# [3] ì¶”ë¡  í•¨ìˆ˜ (LoRA ì ìš© ë²„ì „)
# ==========================================
def inference(model_path, test_loader):
    print(f"   Derived from: {model_path}")
    
    # 1. LoRA Config ë¡œë“œ (Base Model ê²½ë¡œ í™•ì¸ìš©)
    peft_config = PeftConfig.from_pretrained(model_path)
    
    # 2. Base Model (KoELECTRA) ë¡œë“œ
    # configì— ì €ì¥ëœ base_model_name_or_pathë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ì›ë³¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    base_model = AutoModelForSequenceClassification.from_pretrained(
        peft_config.base_model_name_or_path, 
        num_labels=2
    )
    
    # 3. LoRA ì–´ëŒ‘í„° ê²°í•© (Base + Adapter)
    model = PeftModel.from_pretrained(base_model, model_path)
    
    model.to(DEVICE)
    model.eval()
    
    predictions = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="   Predicting"):
            input_ids = batch['input_ids'].to(DEVICE)
            attention_mask = batch['attention_mask'].to(DEVICE)
            
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            
            # Logits ì¶”ì¶œ
            if hasattr(outputs, 'logits'):
                logits = outputs.logits
            else:
                logits = outputs[0]
            
            # Softmax: Logits -> Probability (í™•ë¥ ê°’ ë³€í™˜)
            probs = torch.nn.functional.softmax(logits, dim=-1)
            predictions.append(probs.cpu().numpy())
            
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model, base_model
    torch.cuda.empty_cache()
    gc.collect()
    
    return np.concatenate(predictions, axis=0)

# ==========================================
# [4] ë©”ì¸ ì‹¤í–‰ (Rank Averaging í†µí•©)
# ==========================================
def main():
    # 1. ë°ì´í„° ë¡œë“œ
    if not os.path.exists(TEST_FILE_PATH):
        print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {TEST_FILE_PATH}")
        return

    test_df = pd.read_csv(TEST_FILE_PATH)
    print(f"ğŸ“‚ Test Data Loaded: {len(test_df)} rows")

    # (1) Text ì»¬ëŸ¼ ì°¾ê¸°
    text_col = None
    candidates = ['text', 'paragraph_text', 'content', 'sentence', 'full_text', 'overview']
    for col in test_df.columns:
        if col.lower() in candidates:
            text_col = col
            break
    
    if text_col:
        test_df.rename(columns={text_col: 'text'}, inplace=True)
    else:
        obj_cols = test_df.select_dtypes(include=['object']).columns
        if len(obj_cols) > 0:
            test_df.rename(columns={obj_cols[0]: 'text'}, inplace=True)
        else:
            print("âŒ [Critical] í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

    # (2) ID ì»¬ëŸ¼ ì°¾ê¸°
    input_id_col = 'id'
    id_candidates = ['id', 'ID', 'idx', 'index', 'no']
    for col in test_df.columns:
        if col in id_candidates: 
            input_id_col = col
            break
    
    # 2. í† í¬ë‚˜ì´ì € ì¤€ë¹„
    first_fold_path = os.path.join(MODEL_ROOT_DIR, "fold0")
    try:
        base_tokenizer = AutoTokenizer.from_pretrained(first_fold_path)
    except:
        print("âš ï¸ ë¡œì»¬ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨. HuggingFace Hubì—ì„œ ë¡œë“œ ì‹œë„.")
        base_tokenizer = AutoTokenizer.from_pretrained("monologg/koelectra-small-v3-discriminator")

    test_dataset = TestDataset(test_df, base_tokenizer, MAX_LEN)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

    # 3. 4-Fold ì•™ìƒë¸” ë° ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
    
    # [ì¤‘ìš”] ê° Foldì˜ ì˜ˆì¸¡ê°’(Class 1 í™•ë¥ )ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    fold_predictions = {} 
    success_folds = 0

    for fold in range(N_FOLDS):
        fold_model_dir = os.path.join(MODEL_ROOT_DIR, f"fold{fold}")
        
        if not os.path.exists(fold_model_dir):
             print(f"âš ï¸ [Skip] ëª¨ë¸ í´ë” ì—†ìŒ: {fold_model_dir}")
             continue
             
        print(f"\nğŸ”„ [Fold {fold}] Inference Start...")
        try:
            # inference í•¨ìˆ˜ëŠ” ìœ„ì—ì„œ ì •ì˜í•œ LoRA ë²„ì „ ì‚¬ìš©
            fold_probs = inference(fold_model_dir, test_loader)
            
            # ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
            # fold_probs[:, 1]ì€ 'AIê°€ ì¼ì„ í™•ë¥ 'ì…ë‹ˆë‹¤.
            fold_predictions[f'Fold_{fold}'] = fold_probs[:, 1]
            success_folds += 1
            
        except Exception as e:
            print(f"âŒ [Error] Fold {fold} ì¶”ë¡  ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

    if success_folds == 0:
        print("âŒ ëª¨ë“  Fold ì¶”ë¡  ì‹¤íŒ¨.")
        return

    # ==========================================
    # 4. ìƒê´€ê´€ê³„(Correlation) ë¶„ì„ ì¶œë ¥
    # ==========================================
    if success_folds > 1:
        print("\n" + "="*40)
        print(" ğŸ“Š Fold ê°„ ìƒê´€ê´€ê³„ ë¶„ì„ (Correlation Matrix)")
        print("="*40)
        
        corr_df = pd.DataFrame(fold_predictions)
        correlation_matrix = corr_df.corr()
        
        print(correlation_matrix)
        print("-" * 40)
        
        min_corr = correlation_matrix.min().min()
        print(f"ğŸ‘‰ ìµœì†Œ ìƒê´€ê³„ìˆ˜: {min_corr:.4f}")
        
        if min_corr < 0.8:
            print("ğŸš¨ ëª¨ë¸ ê°„ ì˜ê²¬ ì°¨ì´ê°€ í½ë‹ˆë‹¤. Rank Averagingì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.")
        else:
            print("âœ… ëª¨ë¸ë“¤ì´ ìœ ì‚¬í•©ë‹ˆë‹¤. Rank Averagingì„ ì¨ë„ ì¢‹ê³  ë‹¨ìˆœ í‰ê· ë„ ì¢‹ìŠµë‹ˆë‹¤.")
        print("="*40 + "\n")

    # ==========================================
    # [í•µì‹¬] 5. ê²°ê³¼ ì €ì¥ (Rank Averaging ì ìš©)
    # ==========================================
    print("âš–ï¸ ìµœì¢… ì•™ìƒë¸”: Rank Averaging ì ìš© ì¤‘...")
    
    final_rank = np.zeros(len(test_df))
    
    for fold_name, preds in fold_predictions.items():
        # ë“±ìˆ˜ ë§¤ê¸°ê¸° (ì‘ì€ ê°’ì´ 1ë“±) -> 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”
        # preds(í™•ë¥ )ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ë“±ìˆ˜(í° ê°’)ë¥¼ ê°€ì ¸ì•¼ í•˜ë¯€ë¡œ rankdata ê·¸ëŒ€ë¡œ ì‚¬ìš©
        # rankdataëŠ” ì‘ì€ ê°’ì— ë‚®ì€ ìˆœìœ„(1), í° ê°’ì— ë†’ì€ ìˆœìœ„(N)ë¥¼ ì¤ë‹ˆë‹¤.
        # AI í™•ë¥ ì´ ë†’ìœ¼ë©´ -> Rank ê°’ì´ ì»¤ì§ -> ìµœì¢… ì ìˆ˜ê°€ ì»¤ì§ (ë§ìŒ)
        normalized_ranks = (rankdata(preds) - 1) / (len(preds) - 1)
        final_rank += normalized_ranks
        
    # ë“±ìˆ˜ í‰ê·  ê³„ì‚°
    avg_rank = final_rank / success_folds

    submission = pd.DataFrame()
    if input_id_col in test_df.columns:
        submission[input_id_col] = test_df[input_id_col]
    else:
        submission['id'] = test_df.index

    # í™•ë¥  ëŒ€ì‹  'ì •ê·œí™”ëœ ìˆœìœ„ í‰ê· 'ì„ ì œì¶œ
    submission['generated'] = avg_rank

    submission.to_csv(OUTPUT_SUBMISSION_PATH, index=False)
    print(f"âœ… Rank Averaging Submission Saved: {OUTPUT_SUBMISSION_PATH}")
    print(submission.head())

if __name__ == "__main__":
    main()