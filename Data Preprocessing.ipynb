{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf72c14f",
   "metadata": {},
   "source": [
    "Train 데이터 셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc81e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DATA_DIR = '/data'\n",
    "# ORIGIN_TRAIN_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "# SEED = 42\n",
    "\n",
    "\n",
    "# df = pd.read_csv(ORIGIN_TRAIN_PATH)\n",
    "# print(f\"원본 데이터 개수: {len(df)}개\")\n",
    "\n",
    "# train_val, local_test = train_test_split(\n",
    "#     df, test_size=0.1, stratify=df['label'], random_state=SEED\n",
    "# )\n",
    "\n",
    "# train, valid = train_test_split(\n",
    "#     train_val, test_size=0.11, stratify=train_val['label'], random_state=SEED\n",
    "# )\n",
    "\n",
    "# print(f\"분할 완료: Train({len(train)}) / Valid({len(valid)}) / Local_Test({len(local_test)})\")\n",
    "\n",
    "# train.to_csv(os.path.join(DATA_DIR, 'train_fixed.csv'), index=False)\n",
    "# valid.to_csv(os.path.join(DATA_DIR, 'valid_fixed.csv'), index=False)\n",
    "# local_test.to_csv(os.path.join(DATA_DIR, 'local_test_fixed.csv'), index=False)\n",
    "\n",
    "# print(\"데이터 분할 및 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207db44e",
   "metadata": {},
   "source": [
    "특수 기호 제거 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# ================\n",
    "#  경로 및 설정\n",
    "# ================\n",
    "DATA_DIR = 'make-model/data'\n",
    "INPUT_FILE = 'train.csv'        # 원본 파일명 (필요시 경로 수정)\n",
    "OUTPUT_FILE = 'clean_train.csv' # 저장할 파일명\n",
    "\n",
    "# ==================\n",
    "# Cleaning 함수 정의\n",
    "# ==================\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # 1. HTML 태그 제거\n",
    "    # 예: <br>, <div> -> \"\"\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # 2. 한자 제거\n",
    "    # 예: 韓國 -> \"\"\n",
    "    text = re.sub(r'[\\u4E00-\\u9FFF]', '', text)\n",
    "\n",
    "    # 3. 빈 괄호 및 내용 없는 괄호 패턴 제거\n",
    "    # 예: (), (  ) -> \"\"\n",
    "    text = re.sub(r'\\(\\s*[^\\w가-힣]*\\s*\\)', '', text)\n",
    "\n",
    "    # 4. ( ? ~ ? ) 형태의 특정 노이즈 패턴 제거\n",
    "    # 예: (?~?), (~?) -> \"\"\n",
    "    text = re.sub(r'\\([^\\(\\)]{0,20}[\\?\\~]{1,3}[^\\(\\)]{0,20}\\)', '', text)\n",
    "\n",
    "    # 5. 반복되는 점(...) 정제 -> 점(.) 하나로 변경\n",
    "    # 무조건 삭제하면 문장의 끝을 알 수 없으므로 축소함\n",
    "    text = re.sub(r'[.,]{3,}', '.', text)\n",
    "\n",
    "    # 6. 반복되는 쉼표(,,,) 정제 -> 쉼표(,) 하나로 변경\n",
    "    text = re.sub(r',\\s*,+', ',', text)\n",
    "\n",
    "    # 7. 중복 괄호((())) 정제 -> 괄호 하나로 변경\n",
    "    # 여는 괄호 중복\n",
    "    text = re.sub(r'\\({2,}', '(', text)\n",
    "    # 닫는 괄호 중복\n",
    "    text = re.sub(r'\\){2,}', ')', text)\n",
    "\n",
    "    # 8. 다중 공백 제거 (하나의 공백으로)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def load_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"파일이 존재하지 않음: {path}\")\n",
    "        return None\n",
    "    \n",
    "    encodings = ['utf-8', 'utf-8-sig', 'cp949']\n",
    "    df = None\n",
    "    \n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            df = pd.read_csv(path, encoding=enc)\n",
    "            print(f\"로드 성공 ({enc}): {path}\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    if df is None:\n",
    "        print(\"데이터 로드 실패\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    input_path = os.path.join(DATA_DIR, INPUT_FILE)\n",
    "    df = load_data(input_path)\n",
    "    \n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    text_col = 'full_text' \n",
    "    if 'full_text' not in df.columns:\n",
    "        for candidate in ['text', 'paragraph_text', 'content']:\n",
    "            if candidate in df.columns:\n",
    "                text_col = candidate\n",
    "                break\n",
    "    \n",
    "    print(f\"텍스트 컬럼 감지됨: {text_col}\")\n",
    "    print(\"데이터 정제 시작...\")\n",
    "\n",
    "    df[text_col] = df[text_col].apply(clean_text)\n",
    "\n",
    "    initial_len = len(df)\n",
    "    df = df[df[text_col].str.strip() != \"\"]\n",
    "    removed_count = initial_len - len(df)\n",
    "    \n",
    "    if removed_count > 0:\n",
    "        print(f\"정제 후 빈 문자열이 된 {removed_count}개 행을 제거함.\")\n",
    "\n",
    "    output_path = os.path.join(DATA_DIR, OUTPUT_FILE)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n정제 완료! 저장된 파일 경로: {output_path}\")\n",
    "    print(f\"총 데이터 개수: {len(df)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ffae0",
   "metadata": {},
   "source": [
    "4fold용 데이터셋 분할\n",
    "1. train -> 0.9 : 0.1(train / test)\n",
    "2. 4fold 0.75 : 0.25(train / valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "# 입력 파일 경로(origin)\n",
    "INPUT_FILE_PATH = 'make-model/data/orgin/clean_train.csv'\n",
    "\n",
    "# 출력 루트 경로\n",
    "OUTPUT_ROOT_DIR = 'make-model/data/fold'\n",
    "\n",
    "# 저장될 파일 이름 설정(변수 앞에 베이스가 되는 데이터 이름 지정)\n",
    "OUTPUT_TEST_FILENAME = 'local_origin_test.csv' \n",
    "OUTPUT_TRAIN_FILENAME = 'origin_train.csv'       \n",
    "OUTPUT_VALID_FILENAME = 'origin_valid.csv'       \n",
    "\n",
    "SEED = 42\n",
    "detected_delimiter = ','\n",
    "detected_quotechar = '\"'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_column_name(columns, candidates):\n",
    "    for col in columns:\n",
    "        if col.lower().strip() in candidates:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def load_and_fix_data(path, is_test=False):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"파일이 없음: {path}\")\n",
    "        return None\n",
    "\n",
    "    df = None\n",
    "    encodings_to_try = ['utf-8-sig', 'utf-8', 'cp949']\n",
    "\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                path,\n",
    "                encoding=encoding,\n",
    "                engine='python',\n",
    "                on_bad_lines='skip',\n",
    "                encoding_errors='ignore',\n",
    "                delimiter=detected_delimiter,\n",
    "                quotechar=detected_quotechar,\n",
    "                quoting=csv.QUOTE_MINIMAL\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            df = None\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"데이터 로드 실패: {path}\")\n",
    "        return None\n",
    "\n",
    "    text_candidates = ['paragraph_text', 'text', 'sentence', 'content', 'full_text']\n",
    "    text_col = find_column_name(df.columns, text_candidates)\n",
    "    if text_col:\n",
    "        df.rename(columns={text_col: 'text'}, inplace=True)\n",
    "    else:\n",
    "        obj_cols = df.select_dtypes(include=['object']).columns\n",
    "        if len(obj_cols) > 0:\n",
    "            df.rename(columns={obj_cols[0]: 'text'}, inplace=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if is_test:\n",
    "        id_candidates = ['id', 'idx', 'index', 'no', 'ID']\n",
    "        id_col = find_column_name(df.columns, id_candidates)\n",
    "        if id_col:\n",
    "            df.rename(columns={id_col: 'id'}, inplace=True)\n",
    "        else:\n",
    "            df['id'] = df.index\n",
    "\n",
    "    if not is_test:\n",
    "        target_candidates = ['generated', 'label', 'target', 'class']\n",
    "        target_col = find_column_name(df.columns, target_candidates)\n",
    "        if target_col:\n",
    "            df.rename(columns={target_col: 'label'}, inplace=True)\n",
    "            try:\n",
    "                df['label'] = df['label'].astype(int)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"타겟(Label) 컬럼을 찾을 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def create_split_and_kfold(input_path, output_root, n_splits=4, test_size=0.1):\n",
    "    print(f\">>> 데이터 처리 시작\")\n",
    "    print(f\"    입력: {input_path}\")\n",
    "    print(f\"    출력 루트: {output_root}\")\n",
    "    print(f\"    파일명 설정: Train[{OUTPUT_TRAIN_FILENAME}], Valid[{OUTPUT_VALID_FILENAME}], Test[{OUTPUT_TEST_FILENAME}]\")\n",
    "    \n",
    "    # 1. 원본 데이터 로드\n",
    "    df = load_and_fix_data(input_path, is_test=False)\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"데이터 로드 실패로 작업을 중단\")\n",
    "        return\n",
    "\n",
    "    print(f\" - 원본 데이터 개수: {len(df)}개\")\n",
    "\n",
    "    # 출력 루트 폴더 생성\n",
    "    if not os.path.exists(output_root):\n",
    "        os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    # 2. [Test Set 분리]\n",
    "    print(f\"\\n[Step 1] Test Set 분리 (비율: {test_size})\")\n",
    "    dev_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=test_size, \n",
    "        stratify=df['label'], \n",
    "        random_state=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Test Set 저장 (변수로 지정한 파일명 사용)\n",
    "    test_save_path = os.path.join(output_root, OUTPUT_TEST_FILENAME)\n",
    "    test_df.to_csv(test_save_path, index=False)\n",
    "    \n",
    "    print(f\" -> Test Set 저장 완료: {test_save_path}\")\n",
    "    print(f\"    (Size: {len(test_df)}, Label 0: {(test_df['label']==0).sum()}, Label 1: {(test_df['label']==1).sum()})\")\n",
    "\n",
    "    # 3. [K-Fold 분할 및 폴더별 저장]\n",
    "    print(f\"\\n[Step 2] {n_splits}-Fold Cross Validation 데이터 생성\")\n",
    "    \n",
    "    dev_df = dev_df.reset_index(drop=True)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(dev_df, dev_df['label'])):\n",
    "        fold_train_df = dev_df.iloc[train_idx]\n",
    "        fold_val_df = dev_df.iloc[val_idx]\n",
    "        \n",
    "        # 폴더 경로 생성 (fold0, fold1 ...)\n",
    "        fold_dir_name = f'fold{fold}'\n",
    "        current_fold_dir = os.path.join(output_root, fold_dir_name)\n",
    "        \n",
    "        if not os.path.exists(current_fold_dir):\n",
    "            os.makedirs(current_fold_dir, exist_ok=True)\n",
    "        \n",
    "        # 파일 저장 (변수로 지정한 파일명 사용)\n",
    "        train_save_path = os.path.join(current_fold_dir, OUTPUT_TRAIN_FILENAME)\n",
    "        val_save_path = os.path.join(current_fold_dir, OUTPUT_VALID_FILENAME)\n",
    "        \n",
    "        fold_train_df.to_csv(train_save_path, index=False)\n",
    "        fold_val_df.to_csv(val_save_path, index=False)\n",
    "        \n",
    "        t_0 = (fold_train_df['label'] == 0).sum()\n",
    "        t_1 = (fold_train_df['label'] == 1).sum()\n",
    "        v_0 = (fold_val_df['label'] == 0).sum()\n",
    "        v_1 = (fold_val_df['label'] == 1).sum()\n",
    "        \n",
    "        print(f\" -> [{fold_dir_name}] 저장 완료\")\n",
    "        print(f\"      Train: {OUTPUT_TRAIN_FILENAME} ({len(fold_train_df)}개)\")\n",
    "        print(f\"      Valid: {OUTPUT_VALID_FILENAME} ({len(fold_val_df)}개)\")\n",
    "\n",
    "    print(\"\\n>>> 모든 작업이 완료되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_split_and_kfold(\n",
    "        input_path=INPUT_FILE_PATH, \n",
    "        output_root=OUTPUT_ROOT_DIR, \n",
    "        n_splits=4, \n",
    "        test_size=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52825ae5",
   "metadata": {},
   "source": [
    "데이터 축소 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18370b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
