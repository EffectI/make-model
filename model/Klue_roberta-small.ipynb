{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a71e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import gc\n",
    "import csv\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback \n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "# colab ì‹¤í–‰ì‹œ ì•„ë˜ ì£¼ì„ í•´ì œ\n",
    "# from google.colab import files\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===========\n",
    "# [ì„¤ì • ë³€ìˆ˜]\n",
    "# ===========\n",
    "BASE_DIR = '/content/drive/MyDrive/model'\n",
    "DATA_DIR = '/content/drive/MyDrive/Data'\n",
    "MODEL_NAME = \"klue/roberta-small\"\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'klue_roberta_small_result')\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 64    \n",
    "EPOCHS = 10         \n",
    "LEARNING_RATE = 5e-5 \n",
    "PATIENCE = 3      \n",
    "TEST_SIZE_RATIO = 0.1 \n",
    "VAL_SIZE_RATIO = 0.11 \n",
    "SEED = 42           \n",
    "\n",
    "detected_delimiter = ','\n",
    "detected_quotechar = '\"'\n",
    "\n",
    "# ==============\n",
    "# [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜]\n",
    "# ==============\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"random seed set to {seed}\")\n",
    "\n",
    "def find_column_name(columns, candidates):\n",
    "    for col in columns:\n",
    "        if col.lower().strip() in candidates:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def load_and_fix_data(path, is_test=False):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}\")\n",
    "        return None\n",
    "\n",
    "    df = None\n",
    "    encodings_to_try = ['utf-8-sig', 'utf-8', 'cp949']\n",
    "\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            print(f\"ë°ì´í„° ë¡œë“œ ì‹œë„: '{encoding}'...\")\n",
    "            df = pd.read_csv(\n",
    "                path,\n",
    "                encoding=encoding,\n",
    "                engine='python',\n",
    "                on_bad_lines='skip',       \n",
    "                encoding_errors='ignore',  \n",
    "                delimiter=detected_delimiter,\n",
    "                quotechar=detected_quotechar,\n",
    "                quoting=csv.QUOTE_MINIMAL\n",
    "            )\n",
    "            print(f\"ë¡œë“œ ì„±ê³µ (ì¸ì½”ë”©: {encoding}, í–‰ ìˆ˜: {len(df)})\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"ì‹¤íŒ¨ ({encoding}): {e}\")\n",
    "            df = None\n",
    "\n",
    "    if df is None:\n",
    "        print(\"ëª¨ë“  ì‹œë„ ëì— ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨.\")\n",
    "        return None\n",
    "\n",
    "    text_candidates = ['paragraph_text', 'text', 'sentence', 'content', 'full_text']\n",
    "    text_col = find_column_name(df.columns, text_candidates)\n",
    "    if text_col:\n",
    "        df.rename(columns={text_col: 'text'}, inplace=True)\n",
    "    else:\n",
    "        obj_cols = df.select_dtypes(include=['object']).columns\n",
    "        if len(obj_cols) > 0:\n",
    "            print(f\"í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ëª» ì°¾ì•„ '{obj_cols[0]}' ì»¬ëŸ¼ì„ ì‚¬ìš©.\")\n",
    "            df.rename(columns={obj_cols[0]: 'text'}, inplace=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if is_test:\n",
    "        id_candidates = ['id', 'idx', 'index', 'no', 'ID']\n",
    "        id_col = find_column_name(df.columns, id_candidates)\n",
    "        if id_col:\n",
    "            df.rename(columns={id_col: 'id'}, inplace=True)\n",
    "        else:\n",
    "            df['id'] = df.index\n",
    "\n",
    "    if not is_test:\n",
    "        target_candidates = ['generated', 'label', 'target', 'class']\n",
    "        target_col = find_column_name(df.columns, target_candidates)\n",
    "        if target_col:\n",
    "            df.rename(columns={target_col: 'label'}, inplace=True)\n",
    "            try:\n",
    "                df['label'] = df['label'].astype(int)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"íƒ€ê²Ÿ(Label) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "\n",
    "    return df\n",
    "\n",
    "def run_colab_process():\n",
    "    set_seeds(SEED)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"\\n[{MODEL_NAME}] í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (Early Stopping + F1)\")\n",
    "\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        print(f\"ğŸ‘‰ '{DATA_DIR}' ê²½ë¡œê°€ ì—†ìŒ /content ì‹¤í–‰\")\n",
    "        current_data_dir = '/content'\n",
    "    else:\n",
    "        current_data_dir = DATA_DIR\n",
    "\n",
    "    full_data_path = os.path.join(current_data_dir, 'train.csv')\n",
    "    full_df = load_and_fix_data(full_data_path, is_test=False) \n",
    "\n",
    "    if full_df is None: return\n",
    "\n",
    "    print(\">>> ë°ì´í„°ì…‹ 3ë‹¨ ë¶„í•  ì¤‘ (Train / Valid / Test)...\")\n",
    "    \n",
    "    train_val_df, test_df = train_test_split(\n",
    "        full_df, \n",
    "        test_size=TEST_SIZE_RATIO, \n",
    "        stratify=full_df['label'], \n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, \n",
    "        test_size=VAL_SIZE_RATIO, \n",
    "        stratify=train_val_df['label'], \n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    print(f\" - Train Set : {len(train_df)}ê°œ\")\n",
    "    print(f\" - Valid Set : {len(val_df)}ê°œ\")\n",
    "    print(f\" - Test Set  : {len(test_df)}ê°œ (ìµœì¢… í‰ê°€ìš©)\")\n",
    "\n",
    "    train_ds = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "    val_ds = Dataset.from_pandas(val_df[['text', 'label']])\n",
    "    test_ds = Dataset.from_pandas(test_df[['text', 'label']])\n",
    "\n",
    "    print(f\">>> í† í¬ë‚˜ì´ì € ë¡œë“œ ({MODEL_NAME})...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    def preprocess(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LEN, padding=False)\n",
    "\n",
    "    encoded_train = train_ds.map(preprocess, batched=True)\n",
    "    encoded_val = val_ds.map(preprocess, batched=True)\n",
    "    encoded_test = test_ds.map(preprocess, batched=True)\n",
    "\n",
    "    print(f\">>> ëª¨ë¸ ë¡œë“œ ({MODEL_NAME})...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        eval_strategy=\"epoch\",     \n",
    "        save_strategy=\"epoch\",     \n",
    "        learning_rate=LEARNING_RATE,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        fp16=True,\n",
    "        load_best_model_at_end=True, \n",
    "        metric_for_best_model=\"f1\",  \n",
    "        greater_is_better=True,      \n",
    "        save_total_limit=2,       \n",
    "        report_to=\"none\",\n",
    "        seed=SEED\n",
    "    )\n",
    "\n",
    "    def compute_metrics(p):\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "        labels = p.label_ids\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds, average='macro')\n",
    "        return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model, args=args,\n",
    "        train_dataset=encoded_train, eval_dataset=encoded_val,\n",
    "        tokenizer=tokenizer, data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
    "    )\n",
    "\n",
    "    print(\">>> í•™ìŠµ ì‹œì‘...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\">>> ëª¨ë¸ ì €ì¥ ì¤‘({OUTPUT_DIR})...\")\n",
    "    trainer.save_model(OUTPUT_DIR)\n",
    "    tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "    print(\">>> ìµœì¢… ì„±ëŠ¥ í‰ê°€ (Test Set)...\")\n",
    "    metrics = trainer.evaluate(encoded_test)\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Final Test Accuracy : {metrics['eval_accuracy']:.4f}\")\n",
    "    print(f\"Final Test F1 Score : {metrics['eval_f1']:.4f}\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "    print(\">>> ìƒì„¸ ì˜ˆì¸¡ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\")\n",
    "    preds_output = trainer.predict(encoded_test)\n",
    "    pred_labels = np.argmax(preds_output.predictions, axis=1)\n",
    "    true_labels = test_df['label'].values\n",
    "    \n",
    "    print(classification_report(true_labels, pred_labels, target_names=['Class 0', 'Class 1']))\n",
    "\n",
    "    print(\">>> ì˜¤ë‹µ ë¶„ì„ìš© CSV ì €ì¥ ì¤‘...\")\n",
    "    test_df['predicted'] = pred_labels\n",
    "    wrong_df = test_df[test_df['label'] != test_df['predicted']]\n",
    "    wrong_save_path = '/content/wrong_predictions.csv'\n",
    "    wrong_df.to_csv(wrong_save_path, index=False)\n",
    "    print(f\"   ì˜¤ë‹µ ë°ì´í„° {len(wrong_df)}ê°œ ì €ì¥ ì™„ë£Œ: {wrong_save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU ì—°ê²° ì„±ê³µ: {torch.cuda.get_device_name(0)}\")\n",
    "        run_colab_process()\n",
    "    else:\n",
    "        print(\"GPU ê°ì§€ê°€ ì•ˆë¨.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929a694c",
   "metadata": {},
   "source": [
    "**submission ìƒì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/model'\n",
    "DATA_DIR = '/content/drive/MyDrive/Data'\n",
    "SAVED_MODEL_NAME = 'klue_roberta_small_result'\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, SAVED_MODEL_NAME)\n",
    "save_csv_path = '/content/temp_submission.csv'\n",
    "\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f\"ëª¨ë¸ ë¡œë“œ ê²½ë¡œ: {OUTPUT_DIR}\")\n",
    "saved_model_path = OUTPUT_DIR\n",
    "test_data_path = os.path.join(DATA_DIR, 'test.csv')\n",
    "\n",
    "if not os.path.exists(test_data_path):\n",
    "    print(f\"'{test_data_path}' íŒŒì¼ì´ ì—†ì–´ /content/test.csvë¡œ ì°¾ìŒ\")\n",
    "    test_data_path = '/content/test.csv'\n",
    "\n",
    "test_df = load_and_fix_data(test_data_path, is_test=True)\n",
    "\n",
    "if test_df is not None:\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(test_df)}í–‰\")\n",
    "    \n",
    "    try:\n",
    "        loaded_model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
    "        loaded_tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "        print(\"ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ ì„±ê³µ\")\n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"   -> ê²½ë¡œ ë° ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸.\")\n",
    "        loaded_model = None\n",
    "\n",
    "    if loaded_model:\n",
    "        test_ds = Dataset.from_pandas(test_df[['text']])\n",
    "\n",
    "        def token_func(examples):\n",
    "            return loaded_tokenizer(examples[\"text\"], truncation=True, max_length=MAX_LEN, padding=False)\n",
    "\n",
    "        encoded_test = test_ds.map(token_func, batched=True)\n",
    "\n",
    "        temp_inference_dir = os.path.join(BASE_DIR, 'temp_inference')\n",
    "        \n",
    "        inference_args = TrainingArguments(\n",
    "            output_dir=temp_inference_dir,\n",
    "            per_device_eval_batch_size=BATCH_SIZE,\n",
    "            fp16=True,\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "\n",
    "        inference_trainer = Trainer(\n",
    "            model=loaded_model,\n",
    "            args=inference_args,\n",
    "            tokenizer=loaded_tokenizer,\n",
    "            data_collator=DataCollatorWithPadding(loaded_tokenizer)\n",
    "        )\n",
    "\n",
    "        print(\">>> ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...\")\n",
    "        pred_output = inference_trainer.predict(encoded_test)\n",
    "\n",
    "        logits = torch.tensor(pred_output.predictions)\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        prob_class_1 = probs[:, 1].numpy() \n",
    "\n",
    "        submission = pd.DataFrame({\n",
    "            'ID': test_df['id'],  \n",
    "            'generated': prob_class_1\n",
    "        })\n",
    "\n",
    "        submission.to_csv(save_csv_path, index=False)\n",
    "\n",
    "        print(f\"\\níŒŒì¼ ìƒì„± ì™„ë£Œ: {save_csv_path}\")\n",
    "        print(submission.head())\n",
    "\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(save_csv_path)\n",
    "        except:\n",
    "            print(\"ìë™ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            pass\n",
    "else:\n",
    "    print(\"test ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
